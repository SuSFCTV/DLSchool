{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgFYFftQKxY5"
   },
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
    "<h3 style=\"text-align: center;\"><b>Базовый поток. Осень 2020</b></h3>\n",
    "\n",
    "<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4RCHGZULaWz"
   },
   "source": [
    "На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2acNQu1L94J"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twe_cnn5KxY6"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD0NXyUYKxY7"
   },
   "source": [
    "Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTa2jNZkKxY8"
   },
   "source": [
    "<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H7wPU0IKxY-"
   },
   "source": [
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    "\n",
    "* Вычислить расстояние до каждого из объектов обучающей выборки\n",
    "* Отобрать объектов обучающей выборки, расстояние до которых минимально\n",
    "* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2docs4225pb"
   },
   "source": [
    "Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcjJQX3wKxZA"
   },
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ozcx5mVOKxZB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ry4bMKaUjHJj"
   },
   "source": [
    "Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rvPrVRvK25pc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2683</td>\n",
       "      <td>333</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>2743</td>\n",
       "      <td>121</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>6572</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2915</td>\n",
       "      <td>90</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>11</td>\n",
       "      <td>4433</td>\n",
       "      <td>232</td>\n",
       "      <td>228</td>\n",
       "      <td>129</td>\n",
       "      <td>4019</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2941</td>\n",
       "      <td>162</td>\n",
       "      <td>7</td>\n",
       "      <td>698</td>\n",
       "      <td>76</td>\n",
       "      <td>2783</td>\n",
       "      <td>227</td>\n",
       "      <td>242</td>\n",
       "      <td>148</td>\n",
       "      <td>1784</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3096</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "      <td>3303</td>\n",
       "      <td>231</td>\n",
       "      <td>202</td>\n",
       "      <td>99</td>\n",
       "      <td>5370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2999</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>488</td>\n",
       "      <td>37</td>\n",
       "      <td>1532</td>\n",
       "      <td>228</td>\n",
       "      <td>225</td>\n",
       "      <td>131</td>\n",
       "      <td>2290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2878</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>417</td>\n",
       "      <td>47</td>\n",
       "      <td>2355</td>\n",
       "      <td>207</td>\n",
       "      <td>218</td>\n",
       "      <td>148</td>\n",
       "      <td>2571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2995</td>\n",
       "      <td>144</td>\n",
       "      <td>8</td>\n",
       "      <td>324</td>\n",
       "      <td>77</td>\n",
       "      <td>2523</td>\n",
       "      <td>232</td>\n",
       "      <td>239</td>\n",
       "      <td>138</td>\n",
       "      <td>1711</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3158</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>480</td>\n",
       "      <td>81</td>\n",
       "      <td>1061</td>\n",
       "      <td>247</td>\n",
       "      <td>221</td>\n",
       "      <td>84</td>\n",
       "      <td>2234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2911</td>\n",
       "      <td>315</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>3522</td>\n",
       "      <td>198</td>\n",
       "      <td>233</td>\n",
       "      <td>175</td>\n",
       "      <td>2407</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2968</td>\n",
       "      <td>212</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>5413</td>\n",
       "      <td>211</td>\n",
       "      <td>250</td>\n",
       "      <td>173</td>\n",
       "      <td>2213</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3274</td>\n",
       "      <td>330</td>\n",
       "      <td>9</td>\n",
       "      <td>537</td>\n",
       "      <td>100</td>\n",
       "      <td>616</td>\n",
       "      <td>198</td>\n",
       "      <td>229</td>\n",
       "      <td>170</td>\n",
       "      <td>458</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3021</td>\n",
       "      <td>147</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5196</td>\n",
       "      <td>235</td>\n",
       "      <td>239</td>\n",
       "      <td>134</td>\n",
       "      <td>1818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2    3    4     5    6    7    8     9  ...  45  46  47  48  \\\n",
       "0   2683  333  35   30   26  2743  121  173  179  6572  ...   0   0   0   0   \n",
       "1   2915   90   8  216   11  4433  232  228  129  4019  ...   0   0   0   0   \n",
       "2   2941  162   7  698   76  2783  227  242  148  1784  ...   0   0   0   0   \n",
       "3   3096   60  17  170    3  3303  231  202   99  5370  ...   0   0   0   0   \n",
       "4   2999   66   8  488   37  1532  228  225  131  2290  ...   0   0   0   0   \n",
       "5   2878    7  11  417   47  2355  207  218  148  2571  ...   0   0   0   0   \n",
       "6   2995  144   8  324   77  2523  232  239  138  1711  ...   1   0   0   0   \n",
       "7   3158  143  28  480   81  1061  247  221   84  2234  ...   0   0   0   0   \n",
       "8   2911  315   8   67    4  3522  198  233  175  2407  ...   0   0   0   0   \n",
       "9   2968  212  10   42    3  5413  211  250  173  2213  ...   0   0   0   0   \n",
       "10  3274  330   9  537  100   616  198  229  170   458  ...   0   0   0   0   \n",
       "11  3021  147  11   42    0  5196  235  239  134  1818  ...   0   0   0   0   \n",
       "\n",
       "    49  50  51  52  53  54  \n",
       "0    0   0   0   0   0   2  \n",
       "1    0   0   0   0   0   1  \n",
       "2    0   0   0   0   0   2  \n",
       "3    0   0   0   0   0   1  \n",
       "4    0   0   0   0   0   2  \n",
       "5    0   0   0   0   0   2  \n",
       "6    0   0   0   0   0   2  \n",
       "7    0   0   0   0   0   1  \n",
       "8    0   0   0   0   0   2  \n",
       "9    0   0   0   0   0   1  \n",
       "10   0   0   0   0   0   1  \n",
       "11   0   0   0   0   0   1  \n",
       "\n",
       "[12 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('forest_dataset.csv')\n",
    "all_data.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_o8yXBPSKxZI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itCWxHEY25pg"
   },
   "source": [
    "Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f_YIUOuV25ph"
   },
   "outputs": [],
   "source": [
    "labels = all_data[all_data.columns[-1]].values\n",
    "feature_matrix = all_data[all_data.columns[:-1]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FukXaH_r8PMQ"
   },
   "source": [
    "### Пара слов о sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5S_0Lfc8PMR"
   },
   "source": [
    "**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhVDEG538PMS"
   },
   "source": [
    "`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJZQulsp8PMT"
   },
   "source": [
    "Познакомимся со вспомогательной функцией \n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "С её помощью можно разбить выборку на обучающую и тестовую части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q030jzyY25pl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkeB47mX8PMY"
   },
   "source": [
    "Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YJN0jFARKxZX"
   },
   "outputs": [],
   "source": [
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n",
    "    feature_matrix, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odC1c7X48PMb"
   },
   "source": [
    "Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3fGvPqG8PMc"
   },
   "source": [
    "Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n",
    "\n",
    "В качестве примера модели можно привести классификаторы\n",
    "[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n",
    "[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuX8Rc7c8PMd"
   },
   "source": [
    "У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYokUkxO8PMe"
   },
   "source": [
    "Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n",
    "\n",
    "У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n",
    "\n",
    "Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n",
    "\n",
    "Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n",
    "\n",
    "Рассмотрим всё это на примере логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ew0Ji_2D8PMe"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c9KcMHXr8PMh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# создание модели с указанием гиперпараметра C\n",
    "clf = LogisticRegression(C=1)\n",
    "# обучение модели\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "# предсказание на тестовой выборке\n",
    "y_pred = clf.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3gjg3pm8PMm"
   },
   "source": [
    "Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J2Ej1Lni8PMn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "malIDW_P8PMp"
   },
   "source": [
    "Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n",
    "\n",
    "Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n",
    "\n",
    "У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vq687Aoc8PMq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OVnqHBvK8PMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# заново создадим модель, указав солвер\n",
    "clf = LogisticRegression(solver='saga')\n",
    "\n",
    "# опишем сетку, по которой будем искать\n",
    "param_grid = {\n",
    "    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# создадим объект GridSearchCV\n",
    "search = GridSearchCV(clf, param_grid, n_jobs=-1, cv=5, refit=True, scoring='accuracy')\n",
    "\n",
    "# запустим поиск\n",
    "search.fit(feature_matrix, labels)\n",
    "\n",
    "# выведем наилучшие параметры\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnVTFcvZ8PMv"
   },
   "source": [
    "В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ArKINrE_8PMw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6419"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okzpKY_I8PMz"
   },
   "source": [
    "Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mdJyxdo8PM1"
   },
   "source": [
    "В заданиях вам предстоит повторить это для метода ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8W__017KxZc"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02uT6CPYKxZe"
   },
   "source": [
    "Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n",
    "\n",
    "* число соседей `n_neighbors`\n",
    "* метрика расстояния между объектами `metric`\n",
    "* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHVNCaJ325qD"
   },
   "source": [
    "Обучите на датасете `KNeighborsClassifier` из `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o4CMnnOY25qD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# Ваш код здесь\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "y_pred = clf.predict(test_feature_matrix)\n",
    "accuracy_score(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_2Mf8BiKxZk"
   },
   "source": [
    "### Вопрос 1:\n",
    "* Какое качество у вас получилось?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFTIaPdrKxZl"
   },
   "source": [
    "Подберём параметры нашей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WzoRJZd25qF"
   },
   "source": [
    "* Переберите по сетке от `1` до `10` параметр числа соседей\n",
    "\n",
    "* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n",
    "\n",
    "* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4lMSy-6f25qG",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=3, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'metric': ['manhattan', 'euclidean'],\n",
       "                         'n_neighbors': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'n_neighbors': np.arange(1,10), \n",
    "    'metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# Теперь обучение. Ваш код здесь\n",
    "clf_grid.fit(train_feature_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SO7E6G8jKxZp"
   },
   "source": [
    "Выведем лучшие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "md48pHrMKxZq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M05n9l8pKxZt"
   },
   "source": [
    "### Вопрос 2:\n",
    "* Какую metric следует использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pmjx38OoKxZt"
   },
   "source": [
    "### Вопрос 3:\n",
    "* Сколько n_neighbors следует использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqLeJUP8KxZu"
   },
   "source": [
    "### Вопрос 4:\n",
    "* Какой тип weights следует использовать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBmiDbvV25qI"
   },
   "source": [
    "Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ig_vS8O925qI"
   },
   "outputs": [],
   "source": [
    "optimal_clf = KNeighborsClassifier(n_neighbors=4, metric = 'manhattan', weights = 'distance')\n",
    "optimal_clf.fit(train_feature_matrix, train_labels)\n",
    "pred_prob = optimal_clf.predict(test_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2kkapT38KxZz"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "unique, freq = np.unique(test_labels, return_counts=True)\n",
    "freq = list(map(lambda x: x / len(test_labels),freq))\n",
    "\n",
    "pred_freq = pred_prob.mean(axis=0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n",
    "plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n",
    "plt.ylim(0, 0.54)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp4uDyLmKxZ3"
   },
   "source": [
    "### Вопрос 5:\n",
    "* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework,adv]knn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
